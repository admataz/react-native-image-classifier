# Tensorflow React Native Camera Image classifier

This is an exeriment with the `Camera` capabilities of  [@tensorflow/tfjs-react-native](https://www.npmjs.com/package/@tensorflow/tfjs-react-native) and using my phone's camera to capture and classify images on the fly. It uses the _mobilenet_ model from Tensorflow. 

Also experimented with capturing predictions from [handpose](https://blog.tensorflow.org/2020/03/face-and-hand-tracking-in-browser-with-mediapipe-and-tensorflowjs.html) (see the commented out code)

## To develop/run locally
Make sure you have [Expo](https://expo.io/learn) installed on your development environment
You will need an ios or android device with the Expo client


- Check out the code from this repository.
- In your terminal, `cd` to the project directory.
- Run `npm install`
- Run `expo r -c`


The expo tools should launch from where you can build and run the example on your phone.


![screenshot]('./screenshot.png) ![screenshot2]('./screenshot2.png)

### Further reading and links

- [TensorFlow.js for React Native is here! â€” The TensorFlow Blog](https://blog.tensorflow.org/2020/02/tensorflowjs-for-react-native-is-here.html?m=1)
- [@tensorflow/tfjs-react-native - npm](https://www.npmjs.com/package/@tensorflow/tfjs-react-native) 
- [TensorFlow.js React Native API](https://js.tensorflow.org/api_react_native/0.2.3/) 


 
 